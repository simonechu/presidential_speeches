---
title: "html_to_df"
author: "Simone Chu"
date: "4/23/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rvest)
library(readr)
library(tidytext)
library(tidyverse)
```


```{r SOTU_unnested}

# FOR SOTU 2019
sotu2019 <- paste(readLines("sotu2019.html"))

sotu2019 <- data.frame(sotu2019, stringsAsFactors = FALSE)

sotu2019_tidy <- sotu2019 %>%
  unnest_tokens(word, sotu2019) %>%
  filter(word != "p")

  # Paragraph breaks were denoted with a "<p>", so I filtered that out because it was recorded
  # as appearing the most frequently. 

sotu2019_sentiment <- sotu2019_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# FOR SOTU 2018
sotu2018 <- paste(readLines("sotu2018.html"))

sotu2018 <- data.frame(sotu2018, stringsAsFactors = FALSE)

sotu2018_tidy <- sotu2018 %>%
  unnest_tokens(word, sotu2018) %>%
  filter(word != "p")

sotu2018_sentiment <- sotu2018_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# FOR SOTU 2016
sotu2016 <- paste(readLines("sotu2016.html"))

sotu2016 <- data.frame(sotu2016, stringsAsFactors = FALSE)

sotu2016_tidy <- sotu2016 %>%
  unnest_tokens(word, sotu2016) %>%
  filter(word != "p")

sotu2016_sentiment <- sotu2016_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# FOR SOTU 2015
sotu2015 <- paste(readLines("sotu2015.html"))

sotu2015 <- data.frame(sotu2015, stringsAsFactors = FALSE)

sotu2015_tidy <- sotu2015 %>%
  unnest_tokens(word, sotu2015) %>%
  filter(word != "p")

sotu2015_sentiment <- sotu2015_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# FOR SOTU 2014
sotu2014 <- paste(readLines("sotu2014.html"))

sotu2014 <- data.frame(sotu2014, stringsAsFactors = FALSE)

sotu2014_tidy <- sotu2014 %>%
  unnest_tokens(word, sotu2014) %>%
  filter(word != "p")

sotu2014_sentiment <- sotu2014_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

```

```{r inaugural_addresses}

# 2017 Inaugural Address - (Same process as for State of the Union!)
i2017 <- paste(readLines("inaugural2017.html"))

i2017 <- data.frame(i2017, stringsAsFactors = FALSE)

i2017_tidy <- i2017 %>%
  unnest_tokens(word, i2017) %>%
  filter(word != "p")

i2017_sentiment <- i2017_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# 2009 Inaugural Address 
i2009 <- paste(readLines("inaugural2009.html"))

i2009 <- data.frame(i2009, stringsAsFactors = FALSE)

i2009_tidy <- i2009 %>%
  unnest_tokens(word, i2009) %>%
  filter(word != "p")

i2009_sentiment <- i2009_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# 2001 Inaugural Address
i2001 <- paste(readLines("inaugural2001.html"))

i2001 <- data.frame(i2001, stringsAsFactors = FALSE)

i2001_tidy <- i2001 %>%
  unnest_tokens(word, i2001) %>%
  filter(word != "p")

i2001_sentiment <- i2001_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# 1993 Inaugural Address
i1993 <- paste(readLines("inaugural1993.html"))

i1993 <- data.frame(i1993, stringsAsFactors = FALSE)

i1993_tidy <- i1993 %>%
  unnest_tokens(word, i1993) %>%
  filter(word != "p")

i1993_sentiment <- i1993_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

```
```{r press}
# NEWS CONFERENCE, PRESIDENT OBAMA
press_obama <- paste(readLines("press_obama_2017-01-18.html"))

press_obama <- data.frame(press_obama, stringsAsFactors = FALSE)

press_obama_tidy <- press_obama %>%
  unnest_tokens(word, press_obama) %>%
  filter(word != "p")

press_obama_sentiment <- press_obama_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# NEWS CONFERENCE, PRESIDENT TRUMP
press_trump <- paste(readLines("press_trump_2017-02-16.html"))

press_trump <- data.frame(press_trump, stringsAsFactors = FALSE)

press_trump_tidy <- press_trump %>%
  unnest_tokens(word, press_trump) %>%
  filter(word != "p")

press_trump_sentiment <- press_trump_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

```


```{r top_tens}

# 2017 Inaugural Address
i2017_topten <- i2017_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  # Make word a factor in order of n
  mutate(word = reorder(word, n)) %>% 
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in Donald Trump's Inaugural Address (2017)",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(i2017_topten, "~/Desktop/presidential_speeches/lets-get-presidential/i2017_topten.rds")

# 2009 Inaugural Address 
i2009_topten <- i2009_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  # Make word a factor in order of n
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in Barack Obama's First Inaugural Address (2009)",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(i2009_topten, "~/Desktop/presidential_speeches/lets-get-presidential/i2009_topten.rds")

# 2001 Inaugural Address 
i2001_topten <- i2001_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  # Make word a factor in order of n
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in George W. Bush's First Inaugural Address (2001)",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(i2001_topten, "~/Desktop/presidential_speeches/lets-get-presidential/i2001_topten.rds")

# 1993 Inaugural Address
i1993_topten <- i1993_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  # Make word a factor in order of n
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in Bill Clinton's First Inaugural Address (1993)",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(i1993_topten, "~/Desktop/presidential_speeches/lets-get-presidential/i1993_topten.rds")

# SOTU 2014
sotu2014_topten <- sotu2014_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in the 2014 State of the Union Address",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(sotu2014_topten, 
          "~/Desktop/presidential_speeches/lets-get-presidential/sotu2014_topten.rds")

# SOTU 2015
sotu2015_topten <- sotu2015_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in the 2015 State of the Union Address",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(sotu2015_topten, 
          "~/Desktop/presidential_speeches/lets-get-presidential/sotu2015_topten.rds")

# SOTU 2016
sotu2016_topten <- sotu2016_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in the 2015 State of the Union Address",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(sotu2016_topten, 
          "~/Desktop/presidential_speeches/lets-get-presidential/sotu2016_topten.rds")

# SOTU 2018
sotu2018_topten <- sotu2018_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in the 2015 State of the Union Address",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(sotu2018_topten, 
          "~/Desktop/presidential_speeches/lets-get-presidential/sotu2018_topten.rds")

# SOTU 2019
sotu2019_topten <- sotu2019_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in the 2019 State of the Union Address",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(sotu2019_topten, 
          "~/Desktop/presidential_speeches/lets-get-presidential/sotu2019_topten.rds")

# OBAMA PRESS
pressobama_topten <- press_obama_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in Pres. Obama's News Conference, Jan. 18, 2017",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(pressobama_topten, 
          "~/Desktop/presidential_speeches/lets-get-presidential/pressobama_topten.rds")

# TRUMP PRESS
presstrump_topten <- press_trump_sentiment %>%
  arrange(desc(n)) %>%
  slice(1:10) %>%
  mutate(word = reorder(word, n)) %>%
  
  ggplot(aes(x = word, y = n, fill = sentiment)) + 
  geom_col() + 
  xlab("Word") + 
  ylab("Number of Instances") + 
  labs(title = "Top 10 Most Used Words in Pres. Trump's News Conference, Feb. 16, 2017",
       fill = "Sentiment") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

write_rds(pressobama_topten, 
          "~/Desktop/presidential_speeches/lets-get-presidential/presstrump_topten.rds")

```


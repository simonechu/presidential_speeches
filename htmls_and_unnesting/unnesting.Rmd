---
title: "html_to_df"
author: "Simone Chu"
date: "4/23/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rvest)
library(tidytext)
library(tidyverse)
```


```{r SOTU_unnested}

# FOR SOTU 2019
sotu2019 <- paste(readLines("sotu2019.html"))

sotu2019 <- data.frame(sotu2019, stringsAsFactors = FALSE)

sotu2019_tidy <- sotu2019 %>%
  unnest_tokens(word, sotu2019) %>%
  filter(word != "p")

  # Paragraph breaks were denoted with a "<p>", so I filtered that out because it was recorded
  # as appearing the most frequently. 

sotu2019_sentiment <- sotu2019_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# FOR SOTU 2018
sotu2018 <- paste(readLines("sotu2018.html"))

sotu2018 <- data.frame(sotu2018, stringsAsFactors = FALSE)

sotu2018_tidy <- sotu2018 %>%
  unnest_tokens(word, sotu2018) %>%
  filter(word != "p")

sotu2018_sentiment <- sotu2018_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# FOR SOTU 2016
sotu2016 <- paste(readLines("sotu2016.html"))

sotu2016 <- data.frame(sotu2016, stringsAsFactors = FALSE)

sotu2016_tidy <- sotu2016 %>%
  unnest_tokens(word, sotu2016) %>%
  filter(word != "p")

sotu2016_sentiment <- sotu2016_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# FOR SOTU 2015
sotu2015 <- paste(readLines("sotu2015.html"))

sotu2015 <- data.frame(sotu2015, stringsAsFactors = FALSE)

sotu2015_tidy <- sotu2015 %>%
  unnest_tokens(word, sotu2015) %>%
  filter(word != "p")

sotu2015_sentiment <- sotu2015_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# FOR SOTU 2014
sotu2014 <- paste(readLines("sotu2014.html"))

sotu2014 <- data.frame(sotu2014, stringsAsFactors = FALSE)

sotu2014_tidy <- sotu2014 %>%
  unnest_tokens(word, sotu2014) %>%
  filter(word != "p")

sotu2014_sentiment <- sotu2014_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

```
```{r inaugural_addresses}

# 2017 Inaugural Address - (Same process as for State of the Union!)
i2017 <- paste(readLines("inaugural2017.html"))

i2017 <- data.frame(i2017, stringsAsFactors = FALSE)

i2017_tidy <- i2017 %>%
  unnest_tokens(word, i2017) %>%
  filter(word != "p")

i2017_sentiment <- i2017_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# 2009 Inaugural Address 
i2009 <- paste(readLines("inaugural2009.html"))

i2009 <- data.frame(i2009, stringsAsFactors = FALSE)

i2009_tidy <- i2009 %>%
  unnest_tokens(word, i2009) %>%
  filter(word != "p")

i2009_sentiment <- i2009_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# 2001 Inaugural Address
i2001 <- paste(readLines("inaugural2001.html"))

i2001 <- data.frame(i2001, stringsAsFactors = FALSE)

i2001_tidy <- i2001 %>%
  unnest_tokens(word, i2001) %>%
  filter(word != "p")

i2001_sentiment <- i2001_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# 1993 Inaugural Address
i1993 <- paste(readLines("inaugural1993.html"))

i1993 <- data.frame(i1993, stringsAsFactors = FALSE)

i1993_tidy <- i1993 %>%
  unnest_tokens(word, i1993) %>%
  filter(word != "p")

i1993_sentiment <- i1993_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

```
```{r press}
# NEWS CONFERENCE, PRESIDENT OBAMA
press_obama <- paste(readLines("press_obama_2017-01-18.html"))

press_obama <- data.frame(press_obama, stringsAsFactors = FALSE)

press_obama_tidy <- press_obama %>%
  unnest_tokens(word, press_obama) %>%
  filter(word != "p")

press_obama_sentiment <- press_obama_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

# NEWS CONFERENCE, PRESIDENT TRUMP
press_trump <- paste(readLines("press_trump_2017-02-16.html"))

press_trump <- data.frame(press_trump, stringsAsFactors = FALSE)

press_trump_tidy <- press_trump %>%
  unnest_tokens(word, press_trump) %>%
  filter(word != "p")

press_trump_sentiment <- press_trump_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment)

```




```{r top_tens}

adaptation_sentiment %>%
  # Group by sentiment
  group_by(sentiment) %>%
  # Take the top 10 for each sentiment
  top_n(10) %>%
  ungroup() %>%
  # Make word a factor in order of n
  mutate(word = reorder(word, n))

```

